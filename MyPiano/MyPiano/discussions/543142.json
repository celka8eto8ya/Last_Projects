[
  {
    "Id": "1237302",
    "ThreadId": "543142",
    "Html": "Matt,<br />\n<br />\nI've been using NAudio to convert WAV files to MP3 with some success.  However, I've come across a problem that I hope you can help me with.  I have some test audio files that when I use NAudio to convert to MP3 it seems not all of the compressed audio is written out.  In my tests, it shows that I lose a second of audio according to my player and I can indeed hear that the WAV is slightly longer.  What I've tried so far:<br />\n<br />\nI. Inside MediaFoundationEncoder.ConvertOneBuffer I detect when a &quot;partial&quot; buffer will be used to generate a sample and pad the remaining buffer with 0's.  It seems to write out the entirety of the audio data plus a section of silence.  I can confirm with an audible test as well as an inspection of the binary data against the &quot;truncated&quot; MP3 (I've seen up to 892 extra non-zero bytes get written out when I pad).  However, I'd question whether all the &quot;zero&quot; bytes are written out.<br />\n<br />\nII. I've tried making the managedBuffer object a dynamic length to match that of the actual &quot;read&quot; bytes from the inputProvider.  This results in the same output as your original code.<br />\n<br />\nIII. I've also tried adjusting the BytesToNsPosition to actually give me the bytes for the next whole &quot;Frame&quot; (because MP3 framerate is 38fps: 26 * waveFormat.BitsPerSample / 8).  This resulted in a buffer size of 52 for my data which basically increased the time to convert and gave the same result as your base source code.<br />\n<br />\nQuestions:<br />\n<ol>\n<li>\nI noticed that for the same input WAV file it appears as if the IMFSinkWriter statistics show that the qwNumSamplesReceived is greater than qwNumSamplesProcessed/Encoded.  Is this expected behavior?  My thought here was that the IMFSinkWriter receives a WriteSample request but won't queue the bytes for write until a &quot;full&quot; sample has been created and thus explains why when I pad the managedBuffer it appears to write the remaining non-zero data.<br />\n</li>\n<li>\nI feel that whatever problem I'm experiencing has to do with the remaining bytes read from the inputProvider (WAVReader in this case) not being able to create a &quot;complete&quot; sample but I don't see a way to calculate what this &quot;complete&quot; sample would need to be.  I know that when encoding bytes it sometimes takes a minimum number of input bytes for the algorithm to work but I also feel this is being done when I call DoFinalize() on the IMFSinkWriter.  Any clarity on the process the Media Foundation goes through would be helpful.<br />\n</li>\n</ol>\nI'm going to post this message both at CodeProject and CodePlex.<br />\n",
    "PostedDate": "2014-04-23T16:07:46.107-07:00",
    "UserRole": null,
    "MarkedAsAnswerDate": null
  },
  {
    "Id": "1237745",
    "ThreadId": "543142",
    "Html": "Ok, I <em>think</em> I've discovered something that might help.  First, I'm using Windows Server 2012 so it might behave differently than Windows 8.  Secondly, the MP3 codec I'm using to encode is listed as &quot;MP3 Encoder ACM Wrapper MFT&quot; in the NAudio WPF Demo App.<br />\n\r<br />\nThe wav file that I'm using to encode has the following code information:\r<br />\n<br />\nCodec: PCM S16 LE (s16l)\r<br />\nChannels: Stereo\r<br />\nSample rate: 44100 Hz\r<br />\nBits per sample: 16\r<br />\n<br />\nInside the Encode method, the IMFSinkWriter sets the IMFMediaType to the inputMediaType.MediaFoundationObject and I suspect this is where something happens in the background to the IMFSinkWriter that causes the last incomplete sample to &quot;get lost&quot;.  The base code sets the managedBuffer equal to the size in bytes of the inputProvider.WaveFormat.averageBytesPerSecond to 176400 bytes (Channels (2) * SampleRate (44100) * BitsPerSample (16) / 8).  It then proceeds to chunk through the inputProvider at 176400 bytes until it gets to the last second of data in the WAV file which is a fraction of a second so the bytes read end up being 118960.\r<br />\n<br />\nBasically, the only way to get those remaining 118960 bytes flushed out to the encoded MP3 stream is to pad the managedBuffer with zeros and then pretend the sample we are adding is a full second in length.  I believe this is because the IMFSinkWriter will not flush any samples smaller than what the IMFMediaType (inputMediaType) value defined (in this case 176400 bytes).  This could be my encoder being used or it could be the IMFSinkWriter failing to perform the flush correctly.\r<br />\n<br />\nI can't attach the sample WAV file, but my MediaFoundationEncoder.cs file changes are below.  I no longer use Matt's BytesToNsDuration method as I am now strictly encoding entire seconds (duration becomes a static int).  Hopefully someone can shed some light on this for me but given the light traffic on these sites I'm hoping this will help someone else in the future.<br />\n",
    "PostedDate": "2014-04-24T13:53:20.723-07:00",
    "UserRole": null,
    "MarkedAsAnswerDate": null
  },
  {
    "Id": "1237746",
    "ThreadId": "543142",
    "Html": "<pre><code>\n\n        private void PerformEncode(IMFSinkWriter writer, int streamIndex, IWaveProvider inputProvider)\n        {\n            int maxLength = inputProvider.WaveFormat.AverageBytesPerSecond;\n            var managedBuffer = new byte[maxLength];\n\n            writer.BeginWriting();\n\n            long position = 0;\n            long duration = 0;\n            do\n            {\n                duration = ConvertOneBuffer(writer, streamIndex, inputProvider, position, managedBuffer);\n                position += duration;\n            } while (duration &gt; 0);\n\n            MF_SINK_WRITER_STATISTICS stats = new MF_SINK_WRITER_STATISTICS();\n            stats.cb = Marshal.SizeOf(stats);\n            bool finished = false;\n\n            while (!finished)\n            {\n                writer.GetStatistics(streamIndex, stats);\n\n                if (stats.dwByteCountQueued == 0)\n                    finished = true;\n                else\n                {\n                    //writer.Flush(streamIndex);\n                    System.Threading.Thread.Sleep(100);\n                }\n            }\n\n            writer.DoFinalize();\n        }\n\n        //A single second duration value in 100ns\n        private static long _singleSecondDuration = 10000000L;\n        private long ConvertOneBuffer(IMFSinkWriter writer, int streamIndex, IWaveProvider inputProvider, long position, byte[] managedBuffer)\n        {\n            IntPtr ptr;\n            int currentLength;\n            int read = inputProvider.Read(managedBuffer, 0, managedBuffer.Length);\n            if (read &gt; 0)\n            {\n                //pad remaining buffer\n                int bufferLength = managedBuffer.Length;\n                for (int i = read; i &lt; managedBuffer.Length; i++)\n                    managedBuffer[i] = 0;\n\n                //Create a media sample\n                IMFSample sample = MediaFoundationApi.CreateSample();\n                sample.SetSampleTime(position);\n                sample.SetSampleDuration(_singleSecondDuration);\n\n                //Add a media buffer\n                IMFMediaBuffer buffer = MediaFoundationApi.CreateMemoryBuffer(bufferLength);\n                buffer.SetCurrentLength(bufferLength);\n                sample.AddBuffer(buffer);\n\n                //Copy the data into the buffer\n                buffer.Lock(out ptr, out bufferLength, out currentLength);\n                Marshal.Copy(managedBuffer, 0, ptr, bufferLength);\n                buffer.Unlock();\n\n                //Write the media sample\n                writer.WriteSample(streamIndex, sample);\n\n                Marshal.ReleaseComObject(sample);\n                Marshal.ReleaseComObject(buffer);\n\n                return _singleSecondDuration;\n            }\n\n            return 0;\n        }</code></pre>\n\n",
    "PostedDate": "2014-04-24T13:54:40.877-07:00",
    "UserRole": null,
    "MarkedAsAnswerDate": null
  },
  {
    "Id": "1239505",
    "ThreadId": "543142",
    "Html": "thanks for this, I'll try to get round to looking at it in more detail for a future NAudio<br />\n",
    "PostedDate": "2014-04-29T12:17:49.64-07:00",
    "UserRole": null,
    "MarkedAsAnswerDate": null
  },
  {
    "Id": "1258960",
    "ThreadId": "543142",
    "Html": "Hi,<br />\n<br />\nI seem to be having the same problem. Some of the audio files are missing the last second or so when converting to MP3.<br />\nIs there an NAudio fix on the way?<br />\n<br />\nUPDATE: I think I solved the problem I had with force flushing the writer buffer:<br />\n<pre><code>        using (var retMs = new MemoryStream())\n        using (var ms = new MemoryStream(wavFile))\n        using (var rdr = new WaveFileReader(ms))\n        using (var wtr = new LameMP3FileWriter(retMs, rdr.WaveFormat, bitRate))\n        {\n            rdr.CopyTo(wtr);\n            wtr.Flush(); // this seems to solve it\n            return retMs.ToArray();\n        }\n</code></pre>\n\nThis still has to go thru tests but it looks good for now.<br />\n",
    "PostedDate": "2014-06-23T09:41:11.247-07:00",
    "UserRole": null,
    "MarkedAsAnswerDate": null
  }
]